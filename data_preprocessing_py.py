# -*- coding: utf-8 -*-
"""Data Preprocessing.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1St9eP6y2rFDNOBFVw7tUS2Ts1LJ26GKw
"""

# Data Preprocessing and Cleaning

import pandas as pd
import numpy as np

# Loading the augmented dataset
df = pd.read_csv('final_ds.csv')


signal_strength_cols = ['gp_strength', 'robi_strength', 'bl_strength']
for col in signal_strength_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')


min_strength = -120  # Weakest signal we got during the data collection
max_strength = -60   # Strongest singnawl we got during the data collection
def correct_signal_strength(x):
    if x > 0 or pd.isnull(x):
        return min_strength
    return x

for col in signal_strength_cols:
    df[col] = df[col].apply(correct_signal_strength).clip(lower=min_strength, upper=max_strength)

# handling missing values
df.dropna(inplace=True)

# Invert signal strengths so that higher values represent better signals
df[signal_strength_cols] = -df[signal_strength_cols]

# Normalize signal strength and data speed columns
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
data_speed_cols = ['gp_speed', 'robi_speed', 'bl_speed']
df[signal_strength_cols + data_speed_cols] = scaler.fit_transform(df[signal_strength_cols + data_speed_cols])

# One-Hot Encode 'traffic' and 'weather'
df = pd.get_dummies(df, columns=['traffic', 'weather'], drop_first=False)

# Save the preprocessed dataset
df.to_csv('preprocessed_dataset.csv', index=False)
print(f"Preprocessed dataset shape: {df.shape}")