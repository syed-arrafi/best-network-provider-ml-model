# -*- coding: utf-8 -*-
"""Final Evaluation and Prediction.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1St9eP6y2rFDNOBFVw7tUS2Ts1LJ26GKw
"""

# Final Evaluation and Prediction

import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import itertools
import joblib
import json
import os

# Function to plot confusion matrix
def plot_confusion_matrix(cm, classes, title='Confusion Matrix'):
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    # Print numbers inside squares
    fmt = 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.show()

# Load the dataset
df = pd.read_csv('feature_engineered_dataset.csv')
print(f"Dataset Loaded. Shape: {df.shape}")

# Define feature columns and target
feature_cols = [
    'temperature', 'longitude', 'latitude',
    'traffic_high', 'traffic_low', 'traffic_moderate',
    'weather_cloudy', 'weather_rain', 'weather_sunny',
    'gp_combined', 'robi_combined', 'bl_combined'
]
X = df[feature_cols]
y = df['best_provider_encoded']

# Load model accuracies
model_accuracies_path = 'best_models/model_accuracies.json'
if os.path.exists(model_accuracies_path):
    with open(model_accuracies_path, 'r') as f:
        model_accuracies = json.load(f)
    print("Loaded models' accuracies.")
else:
    raise FileNotFoundError(f"'{model_accuracies_path}' not found. Ensure that the training script has been executed and the file exists.")

# Identify the best model based on mean cross-validation accuracy
best_model_name = max(model_accuracies, key=model_accuracies.get)
print(f"Best Model Identified: {best_model_name}")

# Load the best model
best_model_filename = f"best_models/best_model_{best_model_name.replace(' ', '_')}.pkl"
if not os.path.exists(best_model_filename):
    raise FileNotFoundError(f"The best model file '{best_model_filename}' does not exist. Ensure that the training script has been executed and the file exists.")
best_model = joblib.load(best_model_filename)
print(f"Loaded Best Model: {best_model_name} from '{best_model_filename}'")

# Load the label encoder
label_encoder_filename = 'best_models/label_encoder.pkl'
if os.path.exists(label_encoder_filename):
    label_encoder = joblib.load(label_encoder_filename)
    print("Label encoder loaded successfully.")
    class_names = label_encoder.classes_
else:
    # If label encoder is not saved, ensure that labels are correctly mapped
    print("Label encoder not found. Using integer labels.")
    class_names = sorted(y.unique())  # Fallback to integer labels

# Split the data into training and testing sets (80-20 split)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Re-train the best model on the training data
print(f"Re-training the best model: {best_model_name} on the training data.")
best_model.fit(X_train, y_train)

# Predict on the test set
y_pred = best_model.predict(X_test)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plot_confusion_matrix(cm, classes=class_names, title=f'Confusion Matrix - {best_model_name}')

# Classification Report
print(f"Classification Report for {best_model_name}:")
print(classification_report(y_test, y_pred, target_names=class_names))

# Predict the best provider for a new data point
# Prepare the new data with the same features used in training
new_data = {
    'temperature': [30],
    'longitude': [90.4298],
    'latitude': [23.7635],
    'traffic_high': [1],
    'traffic_low': [0],
    'traffic_moderate': [0],
    'weather_cloudy': [0],
    'weather_rain': [0],
    'weather_sunny': [1],
    'gp_combined': [0.65],
    'robi_combined': [0.55],
    'bl_combined': [0.66]
}

new_df = pd.DataFrame(new_data)

# Predict using the best model
prediction = best_model.predict(new_df)
if 'label_encoder' in locals() and label_encoder is not None:
    best_provider = label_encoder.inverse_transform(prediction)
else:
    best_provider = prediction  # If labels are already interpretable

print(f"\nPredicted Best Provider: {best_provider[0]}")