# -*- coding: utf-8 -*-
"""Data Augmentation.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1St9eP6y2rFDNOBFVw7tUS2Ts1LJ26GKw
"""

# Data Augmentation using Gaussian Copula
!pip install copulas
import pandas as pd
from copulas.multivariate import GaussianMultivariate
from sklearn.preprocessing import LabelEncoder

df_original = pd.read_csv('network.csv')

numerical_features = ['temperature', 'longitude', 'latitude', 'gp_strength', 'robi_strength', 'bl_strength', 'gp_speed', 'robi_speed', 'bl_speed']
categorical_features = ['traffic', 'weather']

# Encoding categorical features numerically for the Copula model
df_encoded = df_original.copy()
label_encoders = {}
for feature in categorical_features:
    le = LabelEncoder()
    df_encoded[feature] = le.fit_transform(df_encoded[feature])
    label_encoders[feature] = le

# Combining features for modeling
model_features = numerical_features + categorical_features

# Fitting Gaussian Copula model
copula_model = GaussianMultivariate()
copula_model.fit(df_encoded[model_features])

# Generating synthetic data 
num_synthetic_samples = 1000
synthetic_data = copula_model.sample(num_synthetic_samples)

# Decoding categorical features in the synthetic data
for feature in categorical_features:
    le = label_encoders[feature]
    synthetic_data[feature] = synthetic_data[feature].round().astype(int)
    synthetic_data[feature] = synthetic_data[feature].clip(0, len(le.classes_) - 1)
    synthetic_data[feature] = le.inverse_transform(synthetic_data[feature])

# Combining original and synthetic datasets
df_augmented = pd.concat([df_original, synthetic_data], ignore_index=True)

# Saving the augmented dataset
df_augmented.to_csv('final_ds.csv', index=False)
print(f"Augmented dataset shape: {df_augmented.shape}")